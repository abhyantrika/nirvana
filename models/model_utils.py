import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torchvision import datasets, transforms
from torch import Tensor

import math 
import numpy as np
from collections import OrderedDict
import os,sys
import clip

def normalize_coordinates(coordinates,img):
	"""
		Normalize coordinates to [-1,1] range.
		Either 2 axes separately or with respect to max dimension.
	"""

	if img.dim() == 3:
		C,H,W = img.shape
	else:
		N,C,H,W = img.shape
	coordinates = coordinates / (max(H,W) - 1) - 0.5		
	coordinates *= 2
	return coordinates

def to_coordinates_and_features(data):
	data = data.squeeze(0) #CHW
	coordinates = torch.ones(data.shape[1:]).nonzero(as_tuple=False).float()
	coordinates = normalize_coordinates(coordinates, data)
	features = data.reshape(data.shape[0], -1).T
	return coordinates, features



class GaussianFourierFeatureTransform(torch.nn.Module):
	"""
	An implementation of Gaussian Fourier feature mapping.

	"Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains":
	   https://arxiv.org/abs/2006.10739
	   https://people.eecs.berkeley.edu/~bmild/fourfeat/index.html

	Given an input of size [batches, num_input_channels, width, height],
	 returns a tensor of size [batches, mapping_size*2, width, height].
	"""

	def __init__(self, num_input_channels, mapping_size=256, scale=10):
		super().__init__()

		self._num_input_channels = num_input_channels
		self._mapping_size = mapping_size
		self._B = torch.randn((num_input_channels, mapping_size)) * scale

	def forward(self, x):
		assert x.dim() == 4, 'Expected 4D input (got {}D input)'.format(x.dim())

		batches, channels, width, height = x.shape

		assert channels == self._num_input_channels,\
			"Expected input to have {} channels (got {} channels)".format(self._num_input_channels, channels)

		# Make shape compatible for matmul with _B.
		# From [B, C, W, H] to [(B*W*H), C].
		x = x.permute(0, 2, 3, 1).reshape(batches * width * height, channels)

		x = x @ self._B.to(x.device)

		# From [(B*W*H), C] to [B, W, H, C]
		x = x.view(batches, width, height, self._mapping_size)
		# From [B, W, H, C] to [B, C, W, H]
		x = x.permute(0, 3, 1, 2)

		x = 2 * np.pi * x
		return torch.cat([torch.sin(x), torch.cos(x)], dim=1)


def get_activation(activation):
	
	if (activation == 'none') or (activation == 'linear') or (activation is None):
		return nn.Identity()

	elif activation.lower() == 'relu':
		return nn.ReLU()
	elif activation.lower() == 'leakyrelu':
		return nn.LeakyReLU()
	elif activation.lower() == 'tanh':
		return nn.Tanh()
	elif activation.lower() == 'sigmoid':
		return nn.Sigmoid()
	else:
		raise ValueError('Unknown activation function {}'.format(activation))


class AdaIN(nn.Module):
	def __init__(self):
		super().__init__()

	def mu(self, x):
		""" Takes a (n,c,h,w) tensor as input and returns the average across
		it's spatial dimensions as (h,w) tensor [See eq. 5 of paper]"""
		return torch.sum(x,(2,3))/(x.shape[2]*x.shape[3])

	def sigma(self, x):
		""" Takes a (n,c,h,w) tensor as input and returns the standard deviation
		across it's spatial dimensions as (h,w) tensor [See eq. 6 of paper] Note
		the permutations are required for broadcasting"""
		return torch.sqrt((torch.sum((x.permute([2,3,0,1])-self.mu(x)).permute([2,3,0,1])**2,(2,3))+0.000000023)/(x.shape[2]*x.shape[3]))

	def forward(self,feature,target_mu,target_sigma):
		"""
			Feature is (N,C,H,W)
		"""
		
		feature_mu = self.mu(feature)
		feature_sigma = self.sigma(feature)
		
		#print(target_mu.shape,target_sigma.shape,feature_mu.shape,feature_sigma.shape)

		return (target_sigma*((feature.permute([2,3,0,1])-feature_mu)/feature_sigma) + target_mu).permute([2,3,0,1])



class Reshape_op(torch.nn.Module):
	def __init__(self, shape):
		super().__init__()
		self.shape = shape
		assert len(shape) == 3
		
	def forward(self, x):
		#breakpoint()
		x = x.view(x.size(0),self.shape[0],self.shape[1],self.shape[2])
		return x

class Sine(nn.Module):
	"""Sine activation with scaling.

	Args:
		w0 (float): Omega_0 parameter from SIREN paper.
	"""
	def __init__(self, w0=1.):
		super().__init__()
		self.w0 = w0

	def forward(self, x):
		return torch.sin(self.w0 * x)


########################
# Initialization methods
def _no_grad_trunc_normal_(tensor, mean, std, a, b):
	# Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
	# grab from upstream pytorch branch and paste here for now
	def norm_cdf(x):
		# Computes standard normal cumulative distribution function
		return (1. + math.erf(x / math.sqrt(2.))) / 2.

	with torch.no_grad():
		# Values are generated by using a truncated uniform distribution and
		# then using the inverse CDF for the normal distribution.
		# Get upper and lower cdf values
		l = norm_cdf((a - mean) / std)
		u = norm_cdf((b - mean) / std)

		# Uniformly fill tensor with values from [l, u], then translate to
		# [2l-1, 2u-1].
		tensor.uniform_(2 * l - 1, 2 * u - 1)

		# Use inverse cdf transform for normal distribution to get truncated
		# standard normal
		tensor.erfinv_()

		# Transform to proper mean, std
		tensor.mul_(std * math.sqrt(2.))
		tensor.add_(mean)

		# Clamp to ensure it's in the proper range
		tensor.clamp_(min=a, max=b)
		return tensor


def init_weights_trunc_normal(m):
	# Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
	if type(m) == BatchLinear or type(m) == nn.Linear:
		if hasattr(m, 'weight'):
			fan_in = m.weight.size(1)
			fan_out = m.weight.size(0)
			std = math.sqrt(2.0 / float(fan_in + fan_out))
			mean = 0.
			# initialize with the same behavior as tf.truncated_normal
			# "The generated values follow a normal distribution with specified mean and
			# standard deviation, except that values whose magnitude is more than 2
			# standard deviations from the mean are dropped and re-picked."
			_no_grad_trunc_normal_(m.weight, mean, std, -2 * std, 2 * std)


def init_weights_normal(m):
	if type(m) == BatchLinear or type(m) == nn.Linear:
		if hasattr(m, 'weight'):
			nn.init.kaiming_normal_(m.weight, a=0.0, nonlinearity='relu', mode='fan_in')


def init_weights_selu(m):
	if type(m) == BatchLinear or type(m) == nn.Linear:
		if hasattr(m, 'weight'):
			num_input = m.weight.size(-1)
			nn.init.normal_(m.weight, std=1 / math.sqrt(num_input))


def init_weights_elu(m):
	if type(m) == BatchLinear or type(m) == nn.Linear:
		if hasattr(m, 'weight'):
			num_input = m.weight.size(-1)
			nn.init.normal_(m.weight, std=math.sqrt(1.5505188080679277) / math.sqrt(num_input))


def init_weights_xavier(m):
	if type(m) == BatchLinear or type(m) == nn.Linear:
		if hasattr(m, 'weight'):
			nn.init.xavier_normal_(m.weight)


def sine_init(m):
	with torch.no_grad():
		if hasattr(m, 'weight'):
			num_input = m.weight.size(-1)
			# See supplement Sec. 1.5 for discussion of factor 30
			m.weight.uniform_(-np.sqrt(6 / num_input) / 30, np.sqrt(6 / num_input) / 30)


def first_layer_sine_init(m):
	with torch.no_grad():
		if hasattr(m, 'weight'):
			num_input = m.weight.size(-1)
			# See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of factor 30
			m.weight.uniform_(-1 / num_input, 1 / num_input)


###################
# Complex operators
def compl_conj(x):
	y = x.clone()
	y[..., 1::2] = -1 * y[..., 1::2]
	return y


def compl_div(x, y):
	''' x / y '''
	a = x[..., ::2]
	b = x[..., 1::2]
	c = y[..., ::2]
	d = y[..., 1::2]

	outr = (a * c + b * d) / (c ** 2 + d ** 2)
	outi = (b * c - a * d) / (c ** 2 + d ** 2)
	out = torch.zeros_like(x)
	out[..., ::2] = outr
	out[..., 1::2] = outi
	return out


def compl_mul(x, y):
	'''  x * y '''
	a = x[..., ::2]
	b = x[..., 1::2]
	c = y[..., ::2]
	d = y[..., 1::2]

	outr = a * c - b * d
	outi = (a + b) * (c + d) - a * c - b * d
	out = torch.zeros_like(x)
	out[..., ::2] = outr
	out[..., 1::2] = outi
	return out
